#!/usr/bin/env python3
"""
Script principal para executar o pipeline ETL completo
Projeto ITBI Recife 2023-2025
"""

import sys
import os
from datetime import datetime

# Adicionar src ao path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.etl.extract import extract_itbi_data, validate_extracted_data
from src.etl.transform import transform_all_datasets
from src.etl.load import consolidate_datasets, save_consolidated_data
from src.utils.data_quality import generate_quality_report

def main():
    """Executa o pipeline ETL completo."""
    
    start_time = datetime.now()
    
    print("ğŸš€ PIPELINE ETL - PROJETO ITBI RECIFE")
    print("=" * 50)
    print(f"InÃ­cio: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    try:
        # FASE 1: EXTRACT
        print("\nğŸ“¥ FASE 1: EXTRACT")
        print("-" * 25)
        
        datasets_raw = extract_itbi_data()
        
        if not validate_extracted_data(datasets_raw):
            raise ValueError("Dados extraÃ­dos falharam na validaÃ§Ã£o")
        
        print("âœ… Extract concluÃ­do com sucesso!")
        
        # FASE 2: TRANSFORM  
        print("\nğŸ”„ FASE 2: TRANSFORM")
        print("-" * 25)
        
        datasets_clean = transform_all_datasets(datasets_raw)
        
        print("âœ… Transform concluÃ­do com sucesso!")
        
        # FASE 3: LOAD
        print("\nğŸ’¾ FASE 3: LOAD")
        print("-" * 25)
        
        df_consolidated = consolidate_datasets(datasets_clean)
        
        # Salvar dados consolidados
        output_path = save_consolidated_data(df_consolidated, "results/datasets")
        
        print("âœ… Load concluÃ­do com sucesso!")
        
        # FASE 4: QUALITY REPORT
        print("\nğŸ“Š FASE 4: RELATÃ“RIO DE QUALIDADE")
        print("-" * 35)
        
        quality_report = generate_quality_report(df_consolidated)
        
        # RESUMO FINAL
        end_time = datetime.now()
        execution_time = end_time - start_time
        
        print("\n" + "=" * 50)
        print("ğŸ¯ PIPELINE ETL CONCLUÃDO COM SUCESSO!")
        print("=" * 50)
        
        print(f"""
ğŸ“Š RESULTADOS:
   â€¢ Registros processados: {len(df_consolidated):,}
   â€¢ Colunas finais: {len(df_consolidated.columns)}
   â€¢ PerÃ­odo: {df_consolidated['source_year'].min()}-{df_consolidated['source_year'].max()}
   â€¢ Arquivo salvo: {output_path}

â±ï¸ PERFORMANCE:
   â€¢ Tempo de execuÃ§Ã£o: {execution_time}
   â€¢ InÃ­cio: {start_time.strftime('%H:%M:%S')}
   â€¢ Fim: {end_time.strftime('%H:%M:%S')}

âœ… STATUS: SUCESSO
        """)
        
        return df_consolidated
        
    except Exception as e:
        print(f"\nâŒ ERRO NO PIPELINE ETL: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    # Criar diretÃ³rios necessÃ¡rios
    os.makedirs("results/datasets", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    
    # Executar pipeline
    result = main()
    
    print("\nğŸ‰ Pipeline ETL executado com sucesso!")
    print("ğŸ“ Verifique os arquivos em results/datasets/")