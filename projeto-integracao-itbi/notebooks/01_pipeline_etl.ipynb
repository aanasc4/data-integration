{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2bedeb",
   "metadata": {},
   "source": [
    "# ğŸ”„ Pipeline ETL - Dados ITBI Recife 2023-2025\n",
    "\n",
    "**Projeto de IntegraÃ§Ã£o de Dados**  \n",
    "**ETL = Extract â†’ Transform â†’ Load**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Objetivo\n",
    "Implementar um pipeline ETL completo para integrar dados do ITBI (Imposto sobre TransmissÃ£o de Bens ImÃ³veis) da cidade do Recife dos anos 2023, 2024 e 2025.\n",
    "\n",
    "## ğŸ”„ DiferenÃ§a ETL vs ELT:\n",
    "- **ETL**: Extract â†’ Transform â†’ Load (transforma durante a extraÃ§Ã£o)\n",
    "- **ELT**: Extract â†’ Load â†’ Transform (carrega dados brutos, transforma no banco)\n",
    "\n",
    "## ğŸ“Š Fontes de Dados:\n",
    "- Portal de Dados Abertos do Recife\n",
    "- Datasets ITBI 2023, 2024, 2025\n",
    "- Formato: CSV com separador ';'\n",
    "\n",
    "## ğŸ¯ Vantagens do ETL:\n",
    "- Controle total sobre transformaÃ§Ãµes\n",
    "- Dados chegam limpos no destino\n",
    "- Menor uso de recursos do banco\n",
    "- ImplementaÃ§Ã£o mais simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdc38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DependÃªncias instaladas e configuradas!\n",
      "ğŸ“… ExecuÃ§Ã£o ETL iniciada em: 2025-07-29 17:16:50\n",
      "ğŸ”„ Pipeline: Extract â†’ Transform â†’ Load\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ… DependÃªncias instaladas e configuradas!\")\n",
    "print(f\"ğŸ“… ExecuÃ§Ã£o ETL iniciada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸ”„ Pipeline: Extract â†’ Transform â†’ Load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cee8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ INICIANDO EXTRAÃ‡ÃƒO DOS DADOS - PIPELINE ETL\n",
      "---------------------------------------------\n",
      "ğŸ” No ETL, extraÃ­mos e validamos os dados\n",
      "\n",
      "ğŸ“… Extraindo dados ITBI 2023...\n",
      "   âœ… Dados extraÃ­dos: 12,669 registros\n",
      "   ğŸ“Š Colunas encontradas: 25\n",
      "   ğŸ“ Metadados adicionados\n",
      "\n",
      "ğŸ“… Extraindo dados ITBI 2024...\n",
      "   âœ… Dados extraÃ­dos: 15,242 registros\n",
      "   ğŸ“Š Colunas encontradas: 25\n",
      "   ğŸ“ Metadados adicionados\n",
      "\n",
      "ğŸ“… Extraindo dados ITBI 2025...\n",
      "   âœ… Dados extraÃ­dos: 7,206 registros\n",
      "   ğŸ“Š Colunas encontradas: 25\n",
      "   ğŸ“ Metadados adicionados\n",
      "\n",
      "âœ… ExtraÃ§Ã£o ETL concluÃ­da:\n",
      "   â€¢ Datasets extraÃ­dos: 3\n",
      "   â€¢ Total de registros: 35,117\n",
      "   â€¢ PrÃ³ximo passo: TRANSFORM (transformaÃ§Ãµes em Python)\n",
      "\n",
      "ğŸ” ESTRUTURA DOS DADOS EXTRAÃDOS:\n",
      "\n",
      "ğŸ“… Dataset 2023:\n",
      "   â€¢ Shape: (12669, 25)\n",
      "   â€¢ MemÃ³ria: 13.43 MB\n",
      "   â€¢ Valores nulos: 8,124\n",
      "   â€¢ Tipos de dados Ãºnicos: 4\n",
      "\n",
      "ğŸ“… Dataset 2024:\n",
      "   â€¢ Shape: (15242, 25)\n",
      "   â€¢ MemÃ³ria: 16.16 MB\n",
      "   â€¢ Valores nulos: 12,681\n",
      "   â€¢ Tipos de dados Ãºnicos: 4\n",
      "\n",
      "ğŸ“… Dataset 2025:\n",
      "   â€¢ Shape: (7206, 25)\n",
      "   â€¢ MemÃ³ria: 7.64 MB\n",
      "   â€¢ Valores nulos: 5,822\n",
      "   â€¢ Tipos de dados Ãºnicos: 4\n"
     ]
    }
   ],
   "source": [
    "def extract_itbi_data_etl():\n",
    "    \"\"\"\n",
    "    Extrai dados ITBI dos 3 anos para o pipeline ETL.\n",
    "    No ETL, extraÃ­mos os dados e aplicamos validaÃ§Ãµes bÃ¡sicas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # URLs dos datasets oficiais\n",
    "    datasets_urls = [\n",
    "        (\"2023\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/d0c08a6f-4c27-423c-9219-8d13403816f4/download/itbi_2023.csv\"),\n",
    "        (\"2024\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/a36d548b-d705-496a-ac47-4ec36f068474/download/itbi_2024.csv\"),\n",
    "        (\"2025\", \"http://dados.recife.pe.gov.br/dataset/28e3e25e-a9a7-4a9f-90a8-bb02d09cbc18/resource/5b582147-3935-459a-bbf7-ee623c22c97b/download/itbi_2025.csv\")\n",
    "    ]\n",
    "    \n",
    "    datasets_dict = {}\n",
    "    total_records = 0\n",
    "    \n",
    "    print(\"ğŸ“¥ INICIANDO EXTRAÃ‡ÃƒO DOS DADOS - PIPELINE ETL\")\n",
    "    print(\"-\" * 45)\n",
    "    print(\"ğŸ” No ETL, extraÃ­mos e validamos os dados\")\n",
    "    \n",
    "    for year, url in datasets_urls:\n",
    "        print(f\"\\nğŸ“… Extraindo dados ITBI {year}...\")\n",
    "        \n",
    "        try:\n",
    "            # Carregar dados com validaÃ§Ãµes\n",
    "            df = pd.read_csv(url, sep=';', encoding='utf-8')\n",
    "            \n",
    "            # Adicionar metadados\n",
    "            df['source_year'] = year\n",
    "            df['extraction_timestamp'] = datetime.now()\n",
    "            df['pipeline_type'] = 'ETL'\n",
    "            \n",
    "            # ValidaÃ§Ãµes bÃ¡sicas durante extraÃ§Ã£o\n",
    "            if df.empty:\n",
    "                raise ValueError(f\"Dataset {year} estÃ¡ vazio\")\n",
    "            \n",
    "            if len(df.columns) < 10:\n",
    "                raise ValueError(f\"Dataset {year} tem poucas colunas: {len(df.columns)}\")\n",
    "            \n",
    "            # Verificar colunas essenciais\n",
    "            required_columns = ['valor_avaliacao', 'bairro', 'data_transacao']\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"   âš ï¸ Colunas essenciais faltando: {missing_columns}\")\n",
    "            \n",
    "            # Armazenar dataset\n",
    "            datasets_dict[year] = df\n",
    "            total_records += len(df)\n",
    "            \n",
    "            print(f\"   âœ… Dados extraÃ­dos: {len(df):,} registros\")\n",
    "            print(f\"   ğŸ“Š Colunas encontradas: {len(df.columns)}\")\n",
    "            print(f\"   ğŸ“ Metadados adicionados\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erro extraindo {year}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nâœ… ExtraÃ§Ã£o ETL concluÃ­da:\")\n",
    "    print(f\"   â€¢ Datasets extraÃ­dos: {len(datasets_dict)}\")\n",
    "    print(f\"   â€¢ Total de registros: {total_records:,}\")\n",
    "    print(f\"   â€¢ PrÃ³ximo passo: TRANSFORM (transformaÃ§Ãµes em Python)\")\n",
    "    \n",
    "    return datasets_dict\n",
    "\n",
    "# Executar extraÃ§Ã£o ETL\n",
    "datasets_raw_etl = extract_itbi_data_etl()\n",
    "\n",
    "# Mostrar estrutura dos dados extraÃ­dos\n",
    "print(\"\\nğŸ” ESTRUTURA DOS DADOS EXTRAÃDOS:\")\n",
    "for year, df in datasets_raw_etl.items():\n",
    "    print(f\"\\nğŸ“… Dataset {year}:\")\n",
    "    print(f\"   â€¢ Shape: {df.shape}\")\n",
    "    print(f\"   â€¢ MemÃ³ria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"   â€¢ Valores nulos: {df.isnull().sum().sum():,}\")\n",
    "    print(f\"   â€¢ Tipos de dados Ãºnicos: {len(df.dtypes.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9da018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FunÃ§Ãµes de transformaÃ§Ã£o ETL definidas!\n"
     ]
    }
   ],
   "source": [
    "def fix_encoding(text):\n",
    "    \"\"\"Corrige problemas de encoding em texto.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    try:\n",
    "        return text.encode('latin1').decode('utf-8')\n",
    "    except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "        return text\n",
    "\n",
    "def convert_currency_format(value):\n",
    "    \"\"\"Converte formato monetÃ¡rio brasileiro para internacional.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    return str(value).replace(',', '.')\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Limpa e padroniza nomes de colunas.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"   ğŸ§¹ Limpando nomes das colunas...\")\n",
    "    \n",
    "    # Manter nomes originais mas criar mapeamento se necessÃ¡rio\n",
    "    original_columns = len(df.columns)\n",
    "    \n",
    "    # Remover colunas completamente vazias\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    removed_columns = original_columns - len(df.columns)\n",
    "    if removed_columns > 0:\n",
    "        print(f\"   â€¢ Colunas vazias removidas: {removed_columns}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"Trata valores nulos no dataset.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"   ğŸ”§ Tratando valores nulos...\")\n",
    "    \n",
    "    # Contar nulos antes\n",
    "    nulls_before = df.isnull().sum().sum()\n",
    "    \n",
    "    # Tratar campos de texto\n",
    "    text_columns = df.select_dtypes(include=['object']).columns\n",
    "    for col in text_columns:\n",
    "        if col not in ['source_year', 'extraction_timestamp', 'pipeline_type']:\n",
    "            df[col] = df[col].fillna('NÃ£o informado')\n",
    "    \n",
    "    # Contar nulos depois\n",
    "    nulls_after = df.isnull().sum().sum()\n",
    "    \n",
    "    print(f\"   â€¢ Nulos tratados: {nulls_before:,} â†’ {nulls_after:,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fix_data_types(df):\n",
    "    \"\"\"Corrige tipos de dados das colunas.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"   ğŸ”¢ Corrigindo tipos de dados...\")\n",
    "    \n",
    "    # Identificar colunas numÃ©ricas por padrÃ£o nos nomes\n",
    "    numeric_patterns = ['valor', 'area', 'ano', 'sfh', 'fracao']\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        \n",
    "        # Se Ã© uma coluna que deve ser numÃ©rica\n",
    "        if any(pattern in col_lower for pattern in numeric_patterns):\n",
    "            if col not in ['source_year', 'extraction_timestamp', 'pipeline_type']:\n",
    "                try:\n",
    "                    # Converter vÃ­rgulas para pontos\n",
    "                    df[col] = df[col].astype(str).str.replace(',', '.')\n",
    "                    # Remover pontos de milhares\n",
    "                    df[col] = df[col].str.replace(r'(\\d)\\.(\\d{3})', r'\\1\\2', regex=True)\n",
    "                    # Converter para float\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                    print(f\"   â€¢ {col}: convertido para numÃ©rico\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸ Erro convertendo {col}: {e}\")\n",
    "    \n",
    "    # Converter datas\n",
    "    date_columns = [col for col in df.columns if 'data' in col.lower()]\n",
    "    for col in date_columns:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            print(f\"   â€¢ {col}: convertido para datetime\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Erro convertendo data {col}: {e}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_derived_metrics(df):\n",
    "    \"\"\"Cria mÃ©tricas derivadas durante a transformaÃ§Ã£o.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"   ğŸ§® Criando mÃ©tricas derivadas...\")\n",
    "    \n",
    "    # Valor por mÂ²\n",
    "    if 'valor_avaliacao' in df.columns and 'area_construida' in df.columns:\n",
    "        df['valor_por_m2'] = (df['valor_avaliacao'] / df['area_construida']).round(2)\n",
    "        print(\"   â€¢ valor_por_m2: criado\")\n",
    "    \n",
    "    # Idade do imÃ³vel\n",
    "    if 'data_transacao' in df.columns and 'ano_construcao' in df.columns:\n",
    "        try:\n",
    "            df['ano_transacao'] = df['data_transacao'].dt.year\n",
    "            df['idade_imovel'] = df['ano_transacao'] - df['ano_construcao']\n",
    "            print(\"   â€¢ idade_imovel: criado\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Erro criando idade_imovel: {e}\")\n",
    "    \n",
    "    # Faixa de valor\n",
    "    if 'valor_avaliacao' in df.columns:\n",
    "        def classificar_valor(valor):\n",
    "            if pd.isna(valor):\n",
    "                return 'NÃ£o informado'\n",
    "            if valor <= 200000:\n",
    "                return 'Baixo (atÃ© R$ 200k)'\n",
    "            elif valor <= 500000:\n",
    "                return 'MÃ©dio (R$ 200k-500k)'\n",
    "            elif valor <= 1000000:\n",
    "                return 'Alto (R$ 500k-1M)'\n",
    "            else:\n",
    "                return 'Premium (acima R$ 1M)'\n",
    "        \n",
    "        df['faixa_valor'] = df['valor_avaliacao'].apply(classificar_valor)\n",
    "        print(\"   â€¢ faixa_valor: criado\")\n",
    "    \n",
    "    # Indicador de financiamento\n",
    "    if 'sfh' in df.columns:\n",
    "        df['tem_financiamento'] = (df['sfh'] > 0).astype(int)\n",
    "        print(\"   â€¢ tem_financiamento: criado\")\n",
    "    \n",
    "    # Componentes temporais\n",
    "    if 'data_transacao' in df.columns:\n",
    "        try:\n",
    "            df['mes_transacao'] = df['data_transacao'].dt.month\n",
    "            df['trimestre'] = df['data_transacao'].dt.quarter\n",
    "            print(\"   â€¢ componentes temporais: criados\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Erro criando componentes temporais: {e}\")\n",
    "    \n",
    "    # Categoria de Ã¡rea\n",
    "    if 'area_construida' in df.columns:\n",
    "        def classificar_area(area):\n",
    "            if pd.isna(area):\n",
    "                return 'NÃ£o informado'\n",
    "            if area <= 50:\n",
    "                return 'Pequeno (atÃ© 50mÂ²)'\n",
    "            elif area <= 100:\n",
    "                return 'MÃ©dio (50-100mÂ²)'\n",
    "            elif area <= 200:\n",
    "                return 'Grande (100-200mÂ²)'\n",
    "            else:\n",
    "                return 'Extra Grande (acima 200mÂ²)'\n",
    "        \n",
    "        df['categoria_area'] = df['area_construida'].apply(classificar_area)\n",
    "        print(\"   â€¢ categoria_area: criado\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ… FunÃ§Ãµes de transformaÃ§Ã£o ETL definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb7ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ INICIANDO TRANSFORMAÃ‡Ã•ES ETL\n",
      "========================================\n",
      "ğŸ¯ No ETL, transformamos os dados EM MEMÃ“RIA antes de carregar\n",
      "\n",
      "ğŸ”„ Transformando dataset 2023 (ETL):\n",
      "-----------------------------------\n",
      "   ğŸ§¹ Limpando nomes das colunas...\n",
      "   ğŸ”§ Tratando valores nulos...\n",
      "   â€¢ Nulos tratados: 8,124 â†’ 6,804\n",
      "   ğŸ”¢ Corrigindo tipos de dados...\n",
      "   â€¢ valor_avaliacao: convertido para numÃ©rico\n",
      "   â€¢ ano_construcao: convertido para numÃ©rico\n",
      "   â€¢ area_terreno: convertido para numÃ©rico\n",
      "   â€¢ area_construida: convertido para numÃ©rico\n",
      "   â€¢ fracao_ideal: convertido para numÃ©rico\n",
      "   â€¢ sfh: convertido para numÃ©rico\n",
      "   â€¢ ano: convertido para numÃ©rico\n",
      "   â€¢ data_transacao: convertido para datetime\n",
      "   ğŸ§® Criando mÃ©tricas derivadas...\n",
      "   â€¢ valor_por_m2: criado\n",
      "   â€¢ idade_imovel: criado\n",
      "   â€¢ faixa_valor: criado\n",
      "   â€¢ tem_financiamento: criado\n",
      "   â€¢ componentes temporais: criados\n",
      "   â€¢ categoria_area: criado\n",
      "   âœ… TransformaÃ§Ã£o 2023 concluÃ­da:\n",
      "      â€¢ Shape: (12669, 25) â†’ (12669, 33)\n",
      "      â€¢ Colunas adicionadas: 8\n",
      "\n",
      "ğŸ”„ Transformando dataset 2024 (ETL):\n",
      "-----------------------------------\n",
      "   ğŸ§¹ Limpando nomes das colunas...\n",
      "   ğŸ”§ Tratando valores nulos...\n",
      "   â€¢ Nulos tratados: 12,681 â†’ 11,238\n",
      "   ğŸ”¢ Corrigindo tipos de dados...\n",
      "   â€¢ valor_avaliacao: convertido para numÃ©rico\n",
      "   â€¢ ano_construcao: convertido para numÃ©rico\n",
      "   â€¢ area_terreno: convertido para numÃ©rico\n",
      "   â€¢ area_construida: convertido para numÃ©rico\n",
      "   â€¢ fracao_ideal: convertido para numÃ©rico\n",
      "   â€¢ sfh: convertido para numÃ©rico\n",
      "   â€¢ ano: convertido para numÃ©rico\n",
      "   â€¢ data_transacao: convertido para datetime\n",
      "   ğŸ§® Criando mÃ©tricas derivadas...\n",
      "   â€¢ valor_por_m2: criado\n",
      "   â€¢ idade_imovel: criado\n",
      "   â€¢ faixa_valor: criado\n",
      "   â€¢ tem_financiamento: criado\n",
      "   â€¢ componentes temporais: criados\n",
      "   â€¢ categoria_area: criado\n",
      "   âœ… TransformaÃ§Ã£o 2024 concluÃ­da:\n",
      "      â€¢ Shape: (15242, 25) â†’ (15242, 33)\n",
      "      â€¢ Colunas adicionadas: 8\n",
      "\n",
      "ğŸ”„ Transformando dataset 2025 (ETL):\n",
      "-----------------------------------\n",
      "   ğŸ§¹ Limpando nomes das colunas...\n",
      "   ğŸ”§ Tratando valores nulos...\n",
      "   â€¢ Nulos tratados: 5,822 â†’ 5,246\n",
      "   ğŸ”¢ Corrigindo tipos de dados...\n",
      "   â€¢ valor_avaliacao: convertido para numÃ©rico\n",
      "   â€¢ ano_construcao: convertido para numÃ©rico\n",
      "   â€¢ area_terreno: convertido para numÃ©rico\n",
      "   â€¢ area_construida: convertido para numÃ©rico\n",
      "   â€¢ fracao_ideal: convertido para numÃ©rico\n",
      "   â€¢ sfh: convertido para numÃ©rico\n",
      "   â€¢ ano: convertido para numÃ©rico\n",
      "   â€¢ data_transacao: convertido para datetime\n",
      "   ğŸ§® Criando mÃ©tricas derivadas...\n",
      "   â€¢ valor_por_m2: criado\n",
      "   â€¢ idade_imovel: criado\n",
      "   â€¢ faixa_valor: criado\n",
      "   â€¢ tem_financiamento: criado\n",
      "   â€¢ componentes temporais: criados\n",
      "   â€¢ categoria_area: criado\n",
      "   âœ… TransformaÃ§Ã£o 2025 concluÃ­da:\n",
      "      â€¢ Shape: (7206, 25) â†’ (7206, 33)\n",
      "      â€¢ Colunas adicionadas: 8\n",
      "\n",
      "âœ… Todas as transformaÃ§Ãµes ETL concluÃ­das!\n",
      "   â±ï¸ Tempo de processamento: 0:00:00.443133\n",
      "   ğŸ’¾ PrÃ³ximo passo: LOAD (carregar dados transformados)\n",
      "\n",
      "ğŸ“Š QUALIDADE DAS TRANSFORMAÃ‡Ã•ES:\n",
      "-----------------------------------\n",
      "\n",
      "ğŸ“… Dataset 2023:\n",
      "   â€¢ Registros: 12,669\n",
      "   â€¢ Colunas: 33\n",
      "   â€¢ MemÃ³ria: 12.41 MB\n",
      "   â€¢ Nulos restantes: 6,804\n",
      "   â€¢ MÃ©tricas derivadas: 4/4\n",
      "\n",
      "ğŸ“… Dataset 2024:\n",
      "   â€¢ Registros: 15,242\n",
      "   â€¢ Colunas: 33\n",
      "   â€¢ MemÃ³ria: 14.91 MB\n",
      "   â€¢ Nulos restantes: 11,238\n",
      "   â€¢ MÃ©tricas derivadas: 4/4\n",
      "\n",
      "ğŸ“… Dataset 2025:\n",
      "   â€¢ Registros: 7,206\n",
      "   â€¢ Colunas: 33\n",
      "   â€¢ MemÃ³ria: 7.05 MB\n",
      "   â€¢ Nulos restantes: 5,246\n",
      "   â€¢ MÃ©tricas derivadas: 4/4\n",
      "\n",
      "ğŸ¯ RESUMO GERAL:\n",
      "   â€¢ Total de registros transformados: 35,117\n",
      "   â€¢ Anos processados: 3\n",
      "   â€¢ Pipeline: Dados transformados EM MEMÃ“RIA\n"
     ]
    }
   ],
   "source": [
    "def transform_dataset_etl(df, year):\n",
    "    \"\"\"Aplica todas as transformaÃ§Ãµes ETL em um dataset.\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ”„ Transformando dataset {year} (ETL):\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # Pipeline de transformaÃ§Ãµes ETL\n",
    "    df = clean_column_names(df)\n",
    "    df = handle_missing_values(df)\n",
    "    df = fix_data_types(df)\n",
    "    df = create_derived_metrics(df)\n",
    "    \n",
    "    final_shape = df.shape\n",
    "    \n",
    "    print(f\"   âœ… TransformaÃ§Ã£o {year} concluÃ­da:\")\n",
    "    print(f\"      â€¢ Shape: {original_shape} â†’ {final_shape}\")\n",
    "    print(f\"      â€¢ Colunas adicionadas: {final_shape[1] - original_shape[1]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_all_datasets_etl(datasets_dict):\n",
    "    \"\"\"Transforma todos os datasets usando ETL.\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ”„ INICIANDO TRANSFORMAÃ‡Ã•ES ETL\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"ğŸ¯ No ETL, transformamos os dados EM MEMÃ“RIA antes de carregar\")\n",
    "    \n",
    "    transformed_datasets = {}\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for year, df in datasets_dict.items():\n",
    "        transformed_df = transform_dataset_etl(df, year)\n",
    "        transformed_datasets[year] = transformed_df\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Todas as transformaÃ§Ãµes ETL concluÃ­das!\")\n",
    "    print(f\"   â±ï¸ Tempo de processamento: {processing_time}\")\n",
    "    print(f\"   ğŸ’¾ PrÃ³ximo passo: LOAD (carregar dados transformados)\")\n",
    "    \n",
    "    return transformed_datasets\n",
    "\n",
    "# Executar transformaÃ§Ãµes ETL\n",
    "datasets_transformed_etl = transform_all_datasets_etl(datasets_raw_etl)\n",
    "\n",
    "# Verificar qualidade das transformaÃ§Ãµes\n",
    "print(\"\\nğŸ“Š QUALIDADE DAS TRANSFORMAÃ‡Ã•ES:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "total_records = 0\n",
    "for year, df in datasets_transformed_etl.items():\n",
    "    print(f\"\\nğŸ“… Dataset {year}:\")\n",
    "    print(f\"   â€¢ Registros: {len(df):,}\")\n",
    "    print(f\"   â€¢ Colunas: {len(df.columns)}\")\n",
    "    print(f\"   â€¢ MemÃ³ria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"   â€¢ Nulos restantes: {df.isnull().sum().sum():,}\")\n",
    "    \n",
    "    # Verificar mÃ©tricas derivadas\n",
    "    derived_metrics = ['valor_por_m2', 'faixa_valor', 'tem_financiamento', 'idade_imovel']\n",
    "    available_metrics = [col for col in derived_metrics if col in df.columns]\n",
    "    print(f\"   â€¢ MÃ©tricas derivadas: {len(available_metrics)}/{len(derived_metrics)}\")\n",
    "    \n",
    "    total_records += len(df)\n",
    "\n",
    "print(f\"\\nğŸ¯ RESUMO GERAL:\")\n",
    "print(f\"   â€¢ Total de registros transformados: {total_records:,}\")\n",
    "print(f\"   â€¢ Anos processados: {len(datasets_transformed_etl)}\")\n",
    "print(f\"   â€¢ Pipeline: Dados transformados EM MEMÃ“RIA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
